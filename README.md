# Integrating Single Frame Depth Recognition with CNNs for Enhanced Vision Assistance to Individuals with Impaired Vision

Navigating daily environments poses a major challenge for 2.2 billion people with visual impairments, limited by inaccurate depth perception in existing assistive technologies. This project proposes a system utilizing Convolutional Neural Networks (CNNs) to enhance depth recognition. I capture 10,000 paired RGB and depth images from diverse environments, training a custom implementation of CNN specifically for depth estimation from RGB images. The trained model will be implemented on a mobile device for real-time processing on live camera feeds at 30 FPS. This depth information can be integrated into an augmented reality interface in the future, providing audio cues and haptic feedback on object location and distance. The project's success will be evaluated through the accuracy of depth estimation compared to ground truth data, aiming for a mean squared error below 10 centimeters. By aiming to develop a portable, real-time depth recognition system, this project aims to improve navigation accuracy, safety, and confidence, ultimately empowering individuals with visual impairments and fostering greater independence and social inclusion. ​​

